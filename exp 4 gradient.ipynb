{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self, lr=0.01, epochs=1000, batch_size=32, tol=1e-3):\n",
        "        self.learning_rate = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.tolerance = tol\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def mean_squared_error(self, y_true, y_pred):\n",
        "        return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "    def gradient(self, X_batch, y_batch):\n",
        "        y_pred = self.predict(X_batch)\n",
        "        error = y_pred - y_batch\n",
        "        gradient_weights = np.dot(X_batch.T, error) / X_batch.shape[0]\n",
        "        gradient_bias = np.mean(error)\n",
        "        return gradient_weights, gradient_bias\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.random.randn(n_features)\n",
        "        self.bias = np.random.randn()\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_shuffled = X[indices]\n",
        "            y_shuffled = y[indices]\n",
        "\n",
        "            for i in range(0, n_samples, self.batch_size):\n",
        "                X_batch = X_shuffled[i:i+self.batch_size]\n",
        "                y_batch = y_shuffled[i:i+self.batch_size]\n",
        "\n",
        "                gradient_weights, gradient_bias = self.gradient(X_batch, y_batch)\n",
        "                self.weights -= self.learning_rate * gradient_weights\n",
        "                self.bias -= self.learning_rate * gradient_bias\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                y_pred = self.predict(X)\n",
        "                loss = self.mean_squared_error(y, y_pred)\n",
        "                print(f\"Epoch {epoch}: Loss {loss}\")\n",
        "\n",
        "            if np.linalg.norm(gradient_weights) < self.tolerance:\n",
        "                print(\"Convergence reached.\")\n",
        "                break\n",
        "\n",
        "        return self.weights, self.bias\n"
      ],
      "metadata": {
        "id": "gRVoKwwz7ANL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random dataset with 100 rows and 5 columns\n",
        "X = np.random.randn(100, 5)\n",
        "# create corresponding target value by adding random\n",
        "# noise in the dataset\n",
        "y = np.dot(X, np.array([1, 2, 3, 4, 5]))\\\n",
        "    + np.random.randn(100) * 0.1\n",
        "# Create an instance of the SGD class\n",
        "model = SGD(lr=0.01, epochs=1000,\n",
        "            batch_size=32, tol=1e-3)\n",
        "w,b=model.fit(X,y)\n",
        "# Predict using predict method from model\n",
        "y_pred = w*X+b\n",
        "#y_pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7GdMpFs8hmP",
        "outputId": "7e0cc74f-8f8e-491e-8215-f8c80dda916d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 81.45788324264794\n",
            "Epoch 100: Loss 0.030059514958443407\n",
            "Epoch 200: Loss 0.009356858402668993\n",
            "Epoch 300: Loss 0.009254091033209351\n",
            "Epoch 400: Loss 0.009260495108998753\n",
            "Epoch 500: Loss 0.009288844748674127\n",
            "Epoch 600: Loss 0.009253827185581471\n",
            "Epoch 700: Loss 0.009263200760247685\n",
            "Epoch 800: Loss 0.009258167465576787\n",
            "Epoch 900: Loss 0.00925870539632353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self, lr=0.001, epochs=2000, batch_size=32, tol=1e-3):\n",
        "        self.learning_rate = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.tolerance = tol\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        return tf.matmul(X, self.weights) + self.bias\n",
        "\n",
        "    def mean_squared_error(self, y_true, y_pred):\n",
        "        return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    def gradient(self, X_batch, y_batch):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self.predict(X_batch)\n",
        "            loss = self.mean_squared_error(y_batch, y_pred)\n",
        "        gradient_weights, gradient_bias = tape.gradient(loss, [self.weights, self.bias])\n",
        "        return gradient_weights, gradient_bias\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = tf.Variable(tf.random.normal((n_features, 1)))\n",
        "        self.bias = tf.Variable(tf.random.normal(()))\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            indices = tf.random.shuffle(tf.range(n_samples))\n",
        "            X_shuffled = tf.gather(X, indices)\n",
        "            y_shuffled = tf.gather(y, indices)\n",
        "\n",
        "            for i in range(0, n_samples, self.batch_size):\n",
        "                X_batch = X_shuffled[i:i+self.batch_size]\n",
        "                y_batch = y_shuffled[i:i+self.batch_size]\n",
        "\n",
        "                gradient_weights, gradient_bias = self.gradient(X_batch, y_batch)\n",
        "                # Gradient clipping\n",
        "                gradient_weights = tf.clip_by_value(gradient_weights, -1, 1)\n",
        "                gradient_bias = tf.clip_by_value(gradient_bias, -1, 1)\n",
        "\n",
        "                self.weights.assign_sub(self.learning_rate * gradient_weights)\n",
        "                self.bias.assign_sub(self.learning_rate * gradient_bias)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                y_pred = self.predict(X)\n",
        "                loss = self.mean_squared_error(y, y_pred)\n",
        "                print(f\"Epoch {epoch}: Loss {loss}\")\n",
        "\n",
        "            if tf.norm(gradient_weights) < self.tolerance:\n",
        "                print(\"Convergence reached.\")\n",
        "                break\n",
        "\n",
        "        return self.weights.numpy(), self.bias.numpy()\n",
        "\n",
        "# Create random dataset with 100 rows and 5 columns\n",
        "X = np.random.randn(100, 5).astype(np.float32)\n",
        "# Create corresponding target value by adding random\n",
        "# noise in the dataset\n",
        "y = np.dot(X, np.array([1, 2, 3, 4, 5], dtype=np.float32)) + np.random.randn(100).astype(np.float32) * 0.1\n",
        "\n",
        "# Create an instance of the SGD class\n",
        "model = SGD(lr=0.005, epochs=1000, batch_size=12, tol=1e-3)\n",
        "w, b = model.fit(X, y)\n",
        "\n",
        "# Predict using predict method from model\n",
        "y_pred = np.dot(X, w) + b\n"
      ],
      "metadata": {
        "id": "cwoow-O-8xBE",
        "outputId": "2e776c02-e445-41d8-ffeb-cde8cd8fe5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 68.17742156982422\n",
            "Epoch 100: Loss 65.45679473876953\n",
            "Epoch 200: Loss 65.3834457397461\n",
            "Epoch 300: Loss 65.32938385009766\n",
            "Epoch 400: Loss 65.40409851074219\n",
            "Epoch 500: Loss 65.42749786376953\n",
            "Epoch 600: Loss 65.39996337890625\n",
            "Epoch 700: Loss 65.32992553710938\n",
            "Epoch 800: Loss 65.40864562988281\n",
            "Epoch 900: Loss 65.41107940673828\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}